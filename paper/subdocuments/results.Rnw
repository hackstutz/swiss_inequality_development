%%%-------------------------------------------------%%%
%%% Sub document results %%%
%%%-------------------------------------------------%%%

\section{Results}



\subsection{Defining income}

\emph{Gini coefficients for taxable income, income before deductions and taxable income after fedaral tax}

<<setup_gini_data>>=
library(foreign)
library(ggplot2)
df <- read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t")
df$zeros <- df$null_norm/df$cpop # i only use normal cases here
@

<<different_ginis>>=
df$G_reink[df$G_reink==1]<-NA
df$G_taxed[df$G_taxed==1]<-NA
library(reshape)
number_ticks <- function(n) {function(limits) pretty(limits, n)}
dflong <- melt(df[,c("G_steink","G_reink","G_taxed","kanton","steuerperiode")], id=c("kanton","steuerperiode"))
names(dflong)[3]<-"Income"
names(dflong)[4]<-"Gini"
levels(dflong$Income)<-c("taxable income","income before deductions","taxable income after tax")
ggplot(dflong[dflong$kanton=="CH",], aes(x=steuerperiode,y=Gini,shape=Income))+
  scale_y_continuous(limits=c(0.3,0.55))+
  scale_x_continuous(limits=c(1982,2012),breaks=number_ticks(10)) +
  geom_point(aes(shape=Income),size=3)+
  geom_line(data=dflong[dflong$kanton=="CH",],aes(linetype=Income))+
  theme_bw()+
  xlab("tax period")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))
#ggplot(dflong, aes(x=steuerperiode,y=Gini,colour=Type))+geom_line()+facet_wrap(~kanton)+theme_bw()+xlab("tax period")
@

\emph{Equivalence scale}

<<setup_data_Brühlhart with and without taxed>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
# Ohne Nuller
bd <- read.csv("../../data/data_Schweiz.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd$Jahr <- as.numeric(substr(bd$Veranlagungsperiode,1,4))
bd$Jahr[nchar(as.character(bd$Veranlagungsperiode))>4] <- bd$Jahr[nchar(as.character(bd$Veranlagungsperiode))>4] - 2
bd<-bd %.% 
  filter(Einheit=="Total")
bd<-subset(bd,Jahr<1995 | Jahr >2002)
bd.long<-reshape(bd,
varying = c("gini_reink","gini_reinka"),
v.names = "Gini",
timevar = "inc_def",
times = c("Net income (only taxed)","Equivalised net income (only taxed)"),
direction ="long")
# mit Nuller
bd.0 <- read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.0<-bd.0 %.% 
  filter(Einheit=="Total")
bd.0<-subset(bd.0,Jahr<1993 | Jahr >2002)
bd.0.long<-reshape(bd.0,
varying = c("gini_reink","gini_reinka"),
v.names = "Gini",
timevar = "inc_def",
times = c("Net income","Equivalised net income"),
direction ="long")
bdlong<-rbind(bd.0.long,bd.long)
names(bdlong)[61]<-"Income"
@

<<equivalencescale>>=
library(ggplot2)
number_ticks <- function(n) {function(limits) pretty(limits, n)}
ggplot(bdlong, aes(x=Jahr,y=Gini,shape=Income))+
  scale_y_continuous(limits=c(0.3,0.55))+
  scale_x_continuous(limits=c(1970,2012),breaks=number_ticks(10)) +
  geom_point(aes(shape=Income),size=3)+
  geom_line(data=bdlong,aes(linetype=Income))+
  theme_bw()+
  xlab("tax period")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))
@

\subsection{Measuring inequality}

% Vergleich über die Zeit da, wo zum ersten Mal Gesamtschweizerische Daten vorliegen bis zur neusten Reihe: 2003 vs 2010

<<setup_data_Brülhart_2003>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
bd.0 <- read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.2003<-bd.0 %.% 
  filter(Jahr==2003,Einheit=="Total")
start <- which(names(bd.2003)=="p1")
end <- which(names(bd.2003)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2003<- data.frame(t(bd.2003[1,start:end]),percentile)
names(bd.2003)[1]=c("inc")
cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
bd.2003 <- rbind(c(0,0),bd.2003)
ival<-bd.2003$inc
perval<-bd.2003$percentile
bd.2003.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))
bd.2003.ind<-bd.2003.ind/1000

# Alt
#####
#prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
#init<-0 
##freq<-100000
#bd.2003$inc<-as.numeric(as.character(bd.2003$inc))
#fin<-(abs(max(bd.2003$inc,na.rm=TRUE))+5)
#ival<-c(init,bd.2003$inc,fin)
#len<-10000
#s<-sapply(2:length(ival),function(i){
#  seq(ival[i-1],ival[i],length.out=len)
#})
#s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
#names(bd.2003.ind)[1]=c("inc")
#3bd.2003.ind<-data.frame(s)
#bd.2003.ind$inc<-bd.2003.ind$inc/1000
#####
@

<<setup_data_Brülhart_2010>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
bd.0 <- read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.2010<-bd.0 %.% 
  filter(Jahr==2010,Einheit=="Total")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))
bd.2010.ind<-bd.2010.ind/1000
@

<<reldist20032010>>=
library(reldist, quietly=TRUE, warn.conflicts = FALSE)

# Probability Density Function

par(mfrow=c(1,2))
density1 <- density(log(bd.2003.ind))
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "log(taxable income)", ylab = "density",
     axes = FALSE)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(0,0),y=c(0.5655167,0.5655167))
legend(fig1legend,lty=1:2,cex=0.7, bty="n",
       legend=c("2003","2010"))
density2 <- density(log(bd.2010.ind))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

# Overall rel dist und median shif effect werden deaktiviert
# g10 <- reldist(y=bd.2010.ind$inc, yo=bd.2003.ind$inc,
#               smooth=0.4, ci=FALSE,
#              ylim=c(0.5,2),
#               yolabs=seq(-1,3,by=0.5),
#               bar=TRUE, quiet=FALSE,
#               xlab="Proportion of 2003 Distribution")
#title(main=paste("Overall realtive density"))
#abline(h=1,lty=2)
#g1A <- reldist(y=bd.2010.ind$inc, yo=bd.2003.ind$inc,
#              show="effect",
#               bar=TRUE, quiet=FALSE,
#               ylim=c(0.5,2), ylab="",
#               smooth=0.4, ci=FALSE,
#               yolabs=seq(-1,3,by=0.5),
#               xlab="Proportion of 2003 Distribution")
#title(main=paste("Effect of Median shift"))
#abline(h=1,lty=2)
gA0 <- reldist(y=bd.2010.ind, yo=bd.2003.ind,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2), ylab="",
               discrete=FALSE,
               xlab="Proportion of 2003 Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))
@

<<polindex20032010>>=
wgt<-rep(1,length(bd.2003.ind))
format(rpy(y=bd.2010.ind,yo=bd.2003.ind,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=bd.2010.ind,yo=bd.2003.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=bd.2010.ind,yo=bd.2003.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

gini(bd.2010.ind)-gini(bd.2003.ind)

@

% Der Vergleich liesse sich auch mit den Perzentilen des Reineinkommens auf der Grundlage der aggregierten ESTV-Daten machen. Dies wäre ein Vorteil, falls die Nuller in den Individual-Daten der ESTV als Nuller geführt sind und nicht mit dem tatsächlichen steuerbaren Einkommen

% FEHLT: Tabelle mit Median, lower und upper polaritätsindex plus Gini bzw. Differenz der Ginis


\subsection{Population coverage}

\subsubsection{Normal versus special cases}

The FTA stopped to publicly report data for special cases after tax period 1993/94. 
For more recent periods however we can compare already calculated percentiles provided by the FTA\footnote{These calculations were done on commission of the FTA within the SNF project Sinergia Nr. 130648 "The Swiss Confederation: A Natural Laboratory for Research on Fiscal and Political Decentralization" by Raphael Parchet and Stefanie Brilon in coordination with Prof. Dr. Marius Brülhart.} which are based on both special and normal cases to normal cases alone.
We will have a look at both, the 1993/94 period as the last period where both 
numbers were reported as well as 2010 where we compare data from the same source (FTA)
but based on different reporting (aggregated data vs. percentiles).

% Variante 1993/1994
<<setup_data_ESTVspecialcases9394, echo=FALSE,warning=FALSE,hide=TRUE>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(ggplot2)
#library(reldist)
normal <- read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t")
normal <- select(normal, -G_reink,-G_taxed,-ppop0,-G_steink0)
#normal <- normal %.% select(-G_reink, -G_taxed, -ppop0, -G_steink0)
pooled <- read.csv("../../data/ginis_und_perzentile_beides.csv",sep="\t")
#special <- read.csv("data/ginis_und_perzentile_sonder.csv",segep="\t")
normal$case <- "normal case"
#special$case <- "special case"
pooled$case <- "pooled, normal and special cases"
d<-rbind(normal,pooled)
d<-d %.% 
  filter(kanton=="CH",steuerperiode==1993.5)

start <- which(names(d)=="p1")
end <- which(names(d)=="p99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,99)
normal <- data.frame(t(d[1,start:end]),percentile,case="normal")
pooled <- data.frame(t(d[2,start:end]),percentile,case="pooled")
names(normal)[1]=c("inc")
names(pooled)[1]=c("inc")
percentiles <- rbind(normal,pooled)  

# imputing pseudo-individual data to use reldist
ival<-na.omit(normal$inc[-1])
perval<-normal$percentile[-1]
normal_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

ival<-na.omit(pooled$inc)
perval<-pooled$percentile[-1]
pooled_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

@

<<specialcases9394, echo=FALSE,warning=FALSE,hide=TRUE>>=
#plot relative distribution

# Probability Density Function

par(mfrow=c(1,2))
density1 <- density(normal_i)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="normal cases vs pooled, normal and special cases 1993/94",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(70,70),y=c(0.016,0.016))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("normal cases","pooled, normal and special cases"),cex=0.5)
density2 <- density(pooled_i)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Overall Reldist and Effect of Median shift
########

#par(mfrow=c(1,3))
#a<-reldist(y=pooled_i, yo=normal_i,
               #smooth=0.4, ci=FALSE,
               #yolabs=seq(-1,3,by=0.5),
              #ylim=c(0.5,2.0),
               #bar=TRUE, quiet=FALSE,
               #xlab="Proportion of Normal-Case-Distribution")
#title(main=paste("Overall relative density 1993/94"))
#abline(h=1,lty=2)
#b<-reldist(y=pooled_i, yo=normal_i,
               #show="effect",
               #bar=TRUE, quiet=FALSE,
               #ylim=c(0.5,2.0), ylab="",
               #smooth=0.4, ci=FALSE,
               #yolabs=seq(-1,3,by=0.5),
               #xlab="Proportion of Normal-Case-Distribution")
#title(main=paste("Effect of Median shift"))
#abline(h=1,lty=2)
######

# Effect of differen shape
c<-reldist(y=pooled_i, yo=normal_i,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))

# Older Versions Rel-Dist-Plots (1993/1994)
########
#ggplot(percentiles, aes(x=percentile,y=inc,group=case,colour=case))+
#  geom_line()+theme_bw()+
#  scale_colour_grey()+
#	xlab("Percentile")+ylab("taxable income")+
#	ggtitle("Taxable incomes of normal and special cases 1993/94")+
#  theme(legend.justification=c(0,1),legend.position=c(0, 1))
# rel <- data.frame(pooled$inc,normal$inc,pooled$percentile)
# rel$change <- rel$pooled.inc/rel$normal.inc
# ggplot(rel, aes(x=pooled.percentile,y=change))+
#	geom_line()+theme_bw()+
#	scale_colour_grey()+
#	geom_line(linetype="dashed",aes(y=1),size=1)+
#	xlab("Percentile")+ylab("taxable income")+
#	ggtitle("Taxable incomes of normal versus special cases 1993/94")
#####

@

<<polindexspecialcases9394>>=
wgt<-rep(1,length(normal_i))
format(rpy(y=pooled_i,yo=normal_i,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=pooled_i,yo=normal_i,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=pooled_i,yo=normal_i,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

gini(pooled_i)-gini(normal_i)
@

1993/94 including special cases changes the distribution slightly at both ends. Special cases have a slightly lower median income and therefore are more frequent in the lower percentiles and less frequent in the upper percentiles. In addition there is an effect of shape: the distribution of special cases is more skewed so that lower percentiles show lower incomes and higher percentiles show higher incomes compared to just normal cases.

% Variante 2010
<<setup_data_specialcases10, echo=FALSE,warning=FALSE,hide=TRUE>>=
library(foreign)
library(ggplot2)
#library(reldist)
normal <- filter(read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t"),kanton=="CH",steuerperiode==2010)
start <- which(names(normal)=="p1")
end <- which(names(normal)=="p99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,99)
normal <- data.frame(t(normal[1,start:end]),percentile)
names(normal)[1]=c("inc")

#bruelhart data
pooled <- filter(read.csv("../../data/data_Schweiz.csv",sep=";"), Veranlagungsperiode==2010, Einheit=="Total")
start <- which(names(pooled)=="p1")
p95 <- which(names(pooled)=="p95")
end <- which(names(pooled)=="p99")
pooled <- data.frame(t(pooled[1,c(start:p95,end)]),percentile)
names(pooled)[1]=c("inc")
pooled$inc<-pooled$inc/1000 #adjust scale
normal$case <- "normal case"
pooled$case <- "pooled, normal and special cases"
percentiles <- rbind(normal,pooled)

# imputing pseudo-individual data to use reldist
# we cut at the 95th percentile because it is unclear what values to use to extrapolate
# (Cutting through omitting na)
ival<-na.omit(c(0,normal$inc))
perval<-c(0,normal$percentile)
normal_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

#nur bis 95
ival<-na.omit(c(0,pooled$inc[-15]))
perval<-c(0,pooled$percentile)
pooled_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))


##Older Versions of Reldist-Plot
######
#ggplot(percentiles, aes(x=percentile,y=inc,group=case,colour=case))+
#  geom_line()+theme_bw()+
#	scale_colour_grey()+
#	xlab("Percentile")+ylab("taxable income")+
#	ggtitle("Taxable incomes of normal and special cases 2010")+
#  theme(legend.justification=c(0,1),legend.position=c(0, 1))
#####
@

<<specialcases10, echo=FALSE,warning=FALSE,hide=TRUE>>=

#Older Version of Relative Distribution plot
######## 
#rel <- data.frame(pooled$inc,normal$inc,pooled$percentile)
#rel$change <- rel$pooled.inc/rel$normal.inc
#ggplot(rel, aes(x=pooled.percentile,y=change))+
	#geom_line()+theme_bw()+
	#geom_line(linetype="dashed",aes(y=1),size=2)+
	#scale_colour_grey()+
	#xlab("Percentile")+ylab("taxable income")+
	#ggtitle("Taxable incomes of normal versus special cases 2010")

#steuerpflichtige estv / stpf bruelhart
#1- (3422210 / 3689063)
######


# Probability Density Function

par(mfrow=c(1,2))
density1 <- density(normal_i)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="normal cases vs pooled, normal and special cases 2010",cex.main=0.9)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(65,65),y=c(0.016,0.016))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("normal cases","pooled, normal and special cases"),cex=0.5)
density2 <- density(pooled_i)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)



# Relative Distribution - Overall and Effect of Median shift
#########

#a<-reldist(y=pooled_i, yo=normal_i,
#               smooth=0.4, ci=FALSE,
#               ylim=c(0.5,2.0),
#               bar=TRUE, quiet=FALSE,
#               xlab="Proportion of Normal-Case-Distribution")
# title(main=paste("Overall relative density 2010"))
# abline(h=1,lty=2)
# b<-reldist(y=pooled_i, yo=normal_i,
#               show="effect",
#               bar=TRUE, quiet=FALSE,
#               ylim=c(0.5,2.0), ylab="",
#               smooth=0.4, ci=FALSE,
#               xlab="Proportion of Normal-Case-Distribution")
# title(main=paste("Effect of Median shift"))
# abline(h=1,lty=2)
######

# Relative Distribution - Effect of different shapes
c<-reldist(y=pooled_i, yo=normal_i,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))
@

<<polindexspecialcases10, echo=FALSE,warning=FALSE,hide=TRUE>>=


wgt<-rep(1,length(normal_i))


format(rpy(y=pooled_i,yo=normal_i,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=pooled_i,yo=normal_i,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=pooled_i,yo=normal_i,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

gini(normal_i)-gini(pooled_i)
@

2010 the picture is similar but more apparent: There is a small effect of median shift lowering incomes in the lowest percentiles. The effect of shape however contributes most.


% Auf neuste Zahlen anpassen

%As we can see from figure~\ref{fig:specialcases93942} and \ref{fig:specialcases092}, special cases differ strongly 
%from normal cases within the low and top percentiles. Within the tax period 1993/94 the fifth percentile of 
%normal cases is 15.8\% higher than the fifth percentile of the combines data while the 95\% percentile of 
%normal cases is even 0.7\% lower if one leaves out special cases. This indicates special cases are very 
%different from normal cases as the share of special cases is only 15.5\%.\footnote{1993/94 there were 2.76 
%million tax units defined as being normal cases compared to 0.51 million special cases.}
%In 2009 the situation has the same pattern. The fifth percentile of normal cases has 11\% higher taxable 
%income compared to data where special cases are included. The five percent top incomes are 4.9\% higher 
%within all cases compared to normal cases only. The share of special cases however decreased 
%to 7.2\%.\footnote{2009: 3.42 million normal cases, 0.27 million special cases}



\emph{taxable income with and without non-taxed}



% Beim Vergleich der Datensätze unterschieden nach nur besteuerten und unter berücksichtigung der nicht besteuerten, stellt sich die Frage wie die unteren Einkommen imputiert werden. Wir haben uns überlegt, dass dies vor allem singles (übrige) betrifft, weil Familien in den unteren Einkommenstabellen bereits sehr selten vorkommen. Deswegen reicht es nur die Untergrenze für singels zu berücksichtigen. Diese liegt 2010 bei 16'900 verändert sich aber über die Zeit

<<with_without_zeros_Gini,warning=FALSE>>=
df <- read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t")
library(reshape)
dflong <- melt(df[,c("G_steink","G_steink0","G_steink_halb","kanton","steuerperiode")], id=c("kanton","steuerperiode"))
names(dflong)[3]<-"Type"
names(dflong)[4]<-"Gini"
levels(dflong$Type)<-c("without zeros","including zeros","imputed values for zeros")
ggplot(dflong[dflong$kanton=="CH" & dflong$steuerperiode>=1995.5,], 
       aes(x=steuerperiode,y=Gini,shape=Type,linetype=Type))+
  scale_y_continuous(limits=c(0.18,0.6))+
  scale_x_continuous(limits=c(1994,2012),breaks=number_ticks(10)) +
  geom_line(size=0.5)+
  geom_point(aes(shape=Type),size=3)+
  theme_bw()+
  xlab("tax period")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))

# Kantonale Unterschiede
#####
#ggplot(dflong[dflong$steuerperiode>=1995.5,], aes(x=steuerperiode,y=Gini,shape=Type,linetype=Type))+geom_line()+facet_wrap(~kanton)+theme_bw()+xlab("tax period")+theme(axis.text.x = element_text(angle = 60, hjust = 1))+theme(legend.justification=c(1,0),legend.position=c(1, 0))
#####
@

% Wenn wir annehmen, dass die Brülhart-Daten, sowohl die unteren als auch die oberen Perzentile angemessen abbildend, dann reicht der Vergleich. Etwas merkwürdig ist es jetzt, wenn wir die Gini-Reihe mit den ESTV Daten machen und dann den Vergleich mit den Brülhartdaten

<<with_without_zeros_RelDist_mitBrülhart,warning=FALSE>>=
bd.2010 <- filter(read.csv("../../data/data_Schweiz.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Total")
bd.0.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Total")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.0.2010<- data.frame(t(bd.0.2010[1,start:end]),percentile)
names(bd.0.2010)[1]=c("inc")

bd.0.2010 <- rbind(c(0,0),bd.0.2010)
ival<-bd.0.2010$inc
perval<-bd.0.2010$percentile
bd.0.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

# Prop-Density Plot
density1 <- density(log(bd.2010.ind))
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="all tax units vs without non-taxed",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(6,6),y=c(0.6,0.6))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("without non-taxed","all tax units"))
density2 <- density(log(bd.0.2010.ind))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

gA0 <- reldist(y=bd.2010.ind, yo=bd.0.2010.ind,
               smooth=0.4, ci=FALSE,
               show="residual",
               entropy=NA,
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2), ylab="",
               yolabs=seq(-1,3,by=0.5),
               discrete=FALSE,
               xlab="Proportion of 2010 Distribution (including non-taxed)")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)


# Polarization index

wgt<-rep(1,length(bd.2010.ind))

format(rpy(y=bd.2010.ind,yo=bd.0.2010.ind,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=bd.2010.ind,yo=bd.0.2010.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=bd.2010.ind,yo=bd.0.2010.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

@

% Wenn etwas bei den unteren Perzentilen nicht stimmt (nicht Besteuerte als Null gewertet), dann müsste der Vergleich mit den ESTV-Nullern gemacht werden.
% Es ist mir aktuell unklar bei welchem Datensazt jetzt die Perzentile mit imputierten Nullern vorliegt.

<<with_without_zeros_RelDist_mitESTV,warning=FALSE>>=

## Nicht fertig angepasst!!!
estvSteink<-(read.csv("../../data/ginis_und_perzentile_normal.csv", header=TRUE,sep="\t"))
estvSteink<-filter(estvSteink,kanton=="CH")
start <- which(names(estvSteink)=="p1")
end <- which(names(estvSteink)=="p9999")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
estvReink<- data.frame(t(estvReink[1,start:end]),percentile)

names(bd.2010)[1]=c("inc")
bd.0.2010<- data.frame(t(bd.0.2010[1,start:end]),percentile)
names(bd.0.2010)[1]=c("inc")

bd.0.2010 <- rbind(c(0,0),bd.0.2010)
ival<-bd.0.2010$inc
perval<-bd.0.2010$percentile
bd.0.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

# Prop-Density Plot
density1 <- density(log(bd.2010.ind))
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="all tax units vs without non-taxed",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(6,6),y=c(0.6,0.6))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("without non-taxed","all tax units"))
density2 <- density(log(bd.0.2010.ind))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

gA0 <- reldist(y=bd.2010.ind, yo=bd.0.2010.ind,
               smooth=0.4, ci=FALSE,
               show="residual",
               entropy=NA,
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2), ylab="",
               yolabs=seq(-1,3,by=0.5),
               discrete=FALSE,
               xlab="Proportion of 2010 Distribution (including non-taxed)")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)


# Polarization index

wgt<-rep(1,length(bd.2010.ind))

format(rpy(y=bd.2010.ind,yo=bd.0.2010.ind,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=bd.2010.ind,yo=bd.0.2010.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=bd.2010.ind,yo=bd.0.2010.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

@


Including zeros leads to significantly higher gini coefficients. However we must keep in mind, that these might be artificially high values as we assume zero income for everyone in the zero group. We can conclude more from the graphic: the ratio between both measures seems to be quite constant although for aggregate Switzerland but there are minor deviations for multiple cantons as well as strong deviations for the cantons Geneva and Ticino. However the problems seem not to result from a shift in the zero-share over time but they are specific for the time-period when the tax system changed. 

\emph{comparison of tax-data and survey data distribution}

<<setup_data Brülhart_mitNuller_und_HABE_2010,warning=FALSE>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
bd.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Total")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010.ind<-bd.2010.ind/1000 # Reskalierung auf 1000er


# HABE - 2010 all cases 

#####################################################
library(reshape)
library(dplyr)
try(habe0911<-read.table("C:/Users/Hackstutz/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(g2009 <- read.csv("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE2009_Gewichte_140625UOe.txt",sep="\t"),silent=TRUE)
try(g2010 <- read.csv("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE2010_Gewichte_140625UOe.txt",sep="\t"),silent=TRUE)
try(g2011 <- read.csv("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE2011_Gewichte_140625UOe.txt",sep="\t"),silent=TRUE)
try(g2009 <- read.csv("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE2009_Gewichte_140625UOe.txt",sep="\t"),silent=TRUE)
try(g2010 <- read.csv("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE2010_Gewichte_140625UOe.txt",sep="\t"),silent=TRUE)
try(g2011 <- read.csv("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE2011_Gewichte_140625UOe.txt",sep="\t"),silent=TRUE)
names(g2009)[3:4]<-c("SRH","Gewicht")
names(g2010)[3:4]<-c("SRH","Gewicht")
names(g2011)[3:4]<-c("SRH","Gewicht")
jg091011 <- rbind(g2009,g2010,g2011)
all.equal(match(jg091011$HaushaltID,habe0911$HaushaltID),1:nrow(habe0911))
habe0911$jahresgewicht <- jg091011$Gewicht

habe10<-subset(habe0911,Jahr08==2010)
habe10$psteink<-habe10$Bruttoeinkommen08+habe10$A31m+habe10$A35m

# Wir brauchen (a) verfügbares Einkommen (b) Bruttoeinkommen und c(Bruttoeinkommen nach Soziversicherungsbeiträgen(A31m) und Monetäre Trasnferausgaben an andere HaushalteA35m)
habe10<-data.frame(habe10$VerfuegbaresEinkommen08*12/1000,habe10$Bruttoeinkommen08*12/1000,habe10$psteink*12/1000,habe10$jahresgewicht)
names(habe10)<-c("inc_habe","brutto","psteink","gew")
habe10$inc_habe[habe10$inc_habe<0]<-0 # One values is -20'000
@


<<BrülhartvsHABE,warning=FALSE>>=
library(ggplot2)
library(reldist, quietly=TRUE, warn.conflicts = FALSE)

# Probability density Function (unterschiedliche Einkommen)
######

#density1 <- density(bd.2010.ind)
#plot(x = (density1$x), y = density1$y, type = "l",
#     xlab = "Einkommen", ylab = "density",
#     axes = FALSE,
#     xlim = c(-30, 800))
#     #ylim=c(0,1.151e-02 ))
#title(main="FTA vs HBS income distribution",cex=0.6)
#axis(side = 1)
#axis(side = 2)
#fig1legend <- list(x=c(400,400),y=c(0.004,0.004))
#legend(fig1legend,lty=1:4,cex=1, bty="n",
#       legend=c("FTA","HBS VerfE","HBS Brutto","HBS Brutto(kor)"))
#density2 <- density(habe10$inc_habe,weights=habe10$gew/sum(habe10$gew))
#lines(x = (density2$x), y = density2$y, type = "l",lty=2)
#density3 <- density(habe10$brutto,weights=habe10$gew/sum(habe10$gew))
#lines(x = (density3$x), y = density3$y, type = "l",lty=3)
#density4 <- density(habe10$psteink,weights=habe10$gew/sum(habe10$gew))
#lines(x = (density4$x), y = density4$y, type = "l",lty=4)
######

par(mfrow=c(1,2))
# Probability density Function (FTA (Brülhart vs HBS Brutto (korrigiert)))
density1 <- density(bd.2010.ind)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "Einkommen", ylab = "density",
     axes = FALSE,
     xlim = c(-30, 800))
     #ylim=c(0,1.151e-02 ))
title(main="FTA vs HBS income distribution",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(400,400),y=c(0.004,0.004))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("FTA","HBS"))
density2 <- density(habe10$psteink,weights=habe10$gew/sum(habe10$gew))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

gA0 <- reldist(y=habe10$psteink, yo=bd.2010.ind,
               ywgt=habe10$gew,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of FTA Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))

########################
# Separate comparison for unmarried

# Select married - ESTV

bd.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Verheiratet / mariés")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010.ind<-bd.2010.ind/1000




# Select married - HABE



habe10.married<-habe0911 %.% 
  filter(Familientyp08>130,Jahr08==2010)
habe10.married$psteink<-habe10.married$Bruttoeinkommen08+habe10.married$A31m+habe10.married$A35m
# Wir brauchen (a) verfügbares Einkommen (b) Bruttoeinkommen und c(Bruttoeinkommen nach Soziversicherungsbeiträgen(A31m) und Monetäre Trasnferausgaben an andere HaushalteA35m)
habe10.married<-data.frame(habe10.married$VerfuegbaresEinkommen08*12/1000,habe10.married$Bruttoeinkommen08*12/1000,habe10.married$psteink*12/1000,habe10.married$jahresgewicht)
names(habe10.married)<-c("inc_habe","brutto","psteink","gew")
habe10.married$inc_habe[habe10.married$inc_habe<0]<-0 # One values is -20'000


# Probability Density Function

par(mfrow=c(1,2))
density1 <- density(bd.2010.ind)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "Einkommen", ylab = "density",
     axes = FALSE,
     xlim = c(min(rbind(density1$x,density2$x)), 800),
     ylim=c(0,max(rbind(density1$y,density2$y))))
title(main="FTA vs HBS income distribution",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(median(rbind(density1$x,density2$x)),median(rbind(density1$x,density2$x))),y=c(max(rbind(density1$y,density2$y)),max(rbind(density1$y,density2$y))))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("HBS","FTA"))
density2 <- density(habe10.married$psteink,weights=habe10.married$gew/sum(habe10.married$gew))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Relative Distribution


gA0 <- reldist(y=habe10.married$inc_habe, yo=bd.2010.ind,
               ywgt=habe10.married$gew,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of FTA Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))


#################
# Separate comparison for unmaried

### Not corrected!!!


bd.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Unverheiratet / non-mariés")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010.ind<-bd.2010.ind/1000


##
# Unmarried ESTV

estv2010.unmarried<-estv2010[c(18:38),c(1,3)]
names(estv2010.unmarried)[2]=c("unmarried")
##
# Simulate individual data points
# Percentile-Plot (descriptive  purpose)
# cumulative probabilites
cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
# probabilities
prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
# extreme values beyond x (to sample)
#freq<-max(normal$anz_pflichtige)
freq<-3000
init<-0
fin<-(abs(max(estv2010.unmarried$unmarried,na.rm=TRUE))+5)
# generate the sequence to take pairs from
ival<-c(init,estv2010.unmarried$unmarried,fin)
len<-10000 # sequence of each pair
s<-sapply(2:length(ival),function(i){
  seq(ival[i-1],ival[i],length.out=len)
})
s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
estv2010.unmarried.ind<-data.frame(s)
names(estv2010.unmarried.ind)[1]=c("inc")
estv2010.unmarried.ind$inc<-estv2010.unmarried.ind$inc/1000


# Select unmarried - HABE
try(habe0911<-read.table("C:/Users/Hackstutz/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
habe10<-habe0911 %.% 
  filter(Jahr08==2010)
habe10.unmarried<-habe0911 %.% 
  filter(Familientyp08<140,Jahr08==2010)
habe10.unmarried<-data.frame(habe10.unmarried$VerfuegbaresEinkommen08)
names(habe10.unmarried)<-"inc_habe"
habe10.unmarried$inc_habe[habe10.unmarried$inc_habe<0]<-0 # One values is -20'000
habe10.unmarried$inc_habe<-habe10.unmarried$inc_habe*12/1000 # transform from monthly income to income per year


# Probability Density Function

density1 <- density(habe10.unmarried$inc_habe)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "Einkommen", ylab = "density",
     axes = FALSE,
     xlim = c(min(rbind(density1$x,density2$x)), 800),
     ylim=c(0,max(rbind(density1$y,density2$y))))
title(main="FTA vs HBS income distribution",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(median(rbind(density1$x,density2$x)),median(rbind(density1$x,density2$x))),y=c(max(rbind(density1$y,density2$y)),max(rbind(density1$y,density2$y))))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("HBS","FTA"))
density2 <- density(bd.2010.ind)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

par(mfrow=c(1,3))
g10 <- reldist(y=estv2010.unmarried.ind$inc, yo=habe10.unmarried$inc_habe,
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               ylim=c(0.5,5.0),
               bar=TRUE, quiet=FALSE,
               xlab="Proportion of HBS Distribution")
title(main=paste("Overall realtive density"))
abline(h=1,lty=2)
g1A <- reldist(y=estv2010.unmarried.ind$inc, yo=habe10.unmarried$inc_habe,
               show="effect",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,5.0), ylab="",
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               xlab="Proportion of HBS Distribution")
title(main=paste("Effect of Median shift"))
abline(h=1,lty=2)
gA0 <- reldist(y=bd.2010.ind, yo=habe10.unmarried$inc_habe,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.5), ylab="",
               xlab="Proportion of HBS Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))
@


\subsection{Intertemporal comparison}



<<benplot>>=
 ### libs
library(reshape, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
library(dplyr)
library(reldist)
library(ggplot2)

### Fetch Ginis from different survey data
number_ticks <- function(n) {function(limits) pretty(limits, n)}
swissGini<-read.csv("../../data/swissGini.csv",header=TRUE,sep=";")

### Ginis from Bens File (for imputed gap)
ben <- filter(read.dta("../../data/estv-gini-kt.dta"),kanton=="CH2")

### and for the rest of Ginis:
estv <- read.dta("../../data/steuerdaten20140522_stata12.dta")

estv_gini <- estv %.% 
  filter(kanton=="CH",eink_art=="Nach steuerbarem Einkommen",fall=="Normalfälle",anz_pflichtige>0,steuerperiode!=1945.5) %.% 
  select(steuerperiode, steink, kanton, eink_ll, eink_ul,anz_pflichtige) %.%
  group_by(factor(steuerperiode)) %.%
  mutate(mean_steink=steink/anz_pflichtige) %.%
  summarise(gini(mean_steink,weights=anz_pflichtige))

names(estv_gini) <- c("Year","FTA")
estv_gini$Year<-as.numeric(as.character(estv_gini$Year))
estv_gini$Year[estv_gini$Year<2003] <- estv_gini$Year[estv_gini$Year<2003]-2


all_gini <- data.frame("Year"=seq(1916,2012,by=0.5))
all_gini$FTA <- estv_gini$FTA[match(all_gini$Year,estv_gini$Year)]
all_gini$HBS <- swissGini$HABE[match(all_gini$Year,swissGini$Year)]
all_gini$EU.SILC <- swissGini$EU.SILC[match(all_gini$Year,swissGini$Year)]
all_gini$LIS <- swissGini$LIS[match(all_gini$Year,swissGini$Year)]
all_gini$FTA_imp <- ben$gini[match(all_gini$Year,ben$jahr)]

all_gini_long<-melt(all_gini,id="Year")

names(all_gini_long) <- c("Year","Data","Gini")
ggplot(data=na.omit(all_gini_long),
  aes(y=Gini,x=Year,shape=Data,linetype=Data))+
  ylab("Gini from different sources") +
  scale_y_continuous(limits=c(0.18,0.4)) +
  scale_x_continuous(limits=c(1915,2012),breaks=number_ticks(10)) +
  geom_point(size=3)+
  geom_line()+
  theme_bw()+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))


@