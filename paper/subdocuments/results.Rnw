%%%-------------------------------------------------%%%
%%% Sub document results %%%
%%%-------------------------------------------------%%%

\section{Results}

% Brauchen wir glaubs nicht mehr
%\textcolor{red}{Gesamtschweizer Grafik (mit imputierten Daten) einmal eine Linie mit Bias, einmal ohne
%Kantonsweise Grafiken
%Kuznets / U-Turn, Test der Hypothesen mit den final Daten. Der link zwischen rein deskriptiv  und Theorie plus Modell ist aktuell noch ein krasser Drahtseilakt...}

% Der Übersicht halber habe ich hier die Titel hier analog zum "Struktur-Issue" auf git gesetzt

\subsection{Defining income}


\emph{Gini coefficients for taxable income, income before deductions and taxable income after tax}

<<setup_gini_data>>=
library(foreign)
library(ggplot2)
df <- read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t")
df$zeros <- df$null_norm/df$cpop # i only use normal cases here
@

<<different_ginis>>=
df$G_reink[df$G_reink==1]<-NA
df$G_taxed[df$G_taxed==1]<-NA
library(reshape)
number_ticks <- function(n) {function(limits) pretty(limits, n)}
dflong <- melt(df[,c("G_steink","G_reink","G_taxed","kanton","steuerperiode")], id=c("kanton","steuerperiode"))
names(dflong)[3]<-"Type"
names(dflong)[4]<-"Gini"
levels(dflong$Type)<-c("taxable income","income before deductions","taxable income after tax")
ggplot(dflong[dflong$kanton=="CH",], aes(x=steuerperiode,y=Gini,shape=Type))+
  scale_y_continuous(limits=c(0.18,0.4))+
  scale_x_continuous(limits=c(1982,2012),breaks=number_ticks(10)) +
  geom_point(aes(shape=Type),size=3)+
  geom_line(data=dflong[dflong$kanton=="CH",],aes(linetype=Type))+
  theme_bw()+
  xlab("tax period")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))
#ggplot(dflong, aes(x=steuerperiode,y=Gini,colour=Type))+geom_line()+facet_wrap(~kanton)+theme_bw()+xlab("tax period")
@

\subsection{Statistical units}

<<setup_data_Brühlhart with and without taxed>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
# Ohne Nuller
bd <- read.csv("../../data/data_Schweiz.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd$Jahr <- as.numeric(substr(bd$Veranlagungsperiode,1,4))
bd$Jahr[nchar(as.character(bd$Veranlagungsperiode))>4] <- bd$Jahr[nchar(as.character(bd$Veranlagungsperiode))>4] - 2
bd<-bd %.% 
  filter(Einheit=="Total")
bd<-subset(bd,Jahr<1995 | Jahr >2002)
bd.long<-reshape(bd,
varying = c("gini_reink","gini_reinka"),
v.names = "Gini",
timevar = "inc_def",
times = c("Net income (only taxed)","Equivalised net income (only taxed)"),
direction ="long")
# mit Nuller
bd.0 <- read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.0<-bd.0 %.% 
  filter(Einheit=="Total")
bd.0<-subset(bd.0,Jahr<1995 | Jahr >2002)
bd.0.long<-reshape(bd.0,
varying = c("gini_reink","gini_reinka"),
v.names = "Gini",
timevar = "inc_def",
times = c("Net income","Equivalised net income"),
direction ="long")
bdlong<-rbind(bd.0.long,bd.long)
@


% Achtung: Das kann doch nicht stimmen, dass wir hier eine Reihe ab 1993 vorliegen haben.
% Die ESTV-Zahlen beginnen ab 1995/1996... Ist das jetzt eine Periode, wo man noch Gesamtschweizerische Reihen rekonstruieren kann?


<<With and without equivalence scale>>=
library(ggplot2)
number_ticks <- function(n) {function(limits) pretty(limits, n)}
ggplot(bdlong, aes(x=Jahr,y=Gini,shape=inc_def))+
  scale_y_continuous(limits=c(0.18,0.6))+
  scale_x_continuous(limits=c(1940,2012),breaks=number_ticks(10)) +
  geom_point(aes(shape=inc_def),size=3)+
  geom_line(data=bdlong,aes(linetype=inc_def))+
  theme_bw()+
  xlab("tax period")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))
@

\subsection{Measuring inequality}

% Es stellt sich die Frage für welchen Zeitraum der Vergleich gemacht wird.
% Ich schlage vor, der Vergleich wird mit den Brülhartdaten gemacht und der Vergleich soll von 2003 bis 2010 reichen

<<setup_data_Brülhart_2003>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
bd.0 <- read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.2003<-bd.0 %.% 
  filter(Jahr==2003,Einheit=="Total")
start <- which(names(bd.2003)=="p1")
end <- which(names(bd.2003)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2003<- data.frame(t(bd.2003[1,start:end]),percentile)
names(bd.2003)[1]=c("inc")
cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
freq<-100000
init<-0 
bd.2003$inc<-as.numeric(as.character(bd.2003$inc))
fin<-(abs(max(bd.2003$inc,na.rm=TRUE))+5)
ival<-c(init,bd.2003$inc,fin)
len<-10000
s<-sapply(2:length(ival),function(i){
  seq(ival[i-1],ival[i],length.out=len)
})
s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
bd.2003.ind<-data.frame(s)
names(bd.2003.ind)[1]=c("inc")
bd.2003.ind$inc<-bd.2003.ind$inc/1000
@

<<setup_data_Brülhart_2010>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
bd.0 <- read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";")
#Veranlagungsperiode -> Jahre
bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.2010<-bd.0 %.% 
  filter(Jahr==2010,Einheit=="Total")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

#cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
#prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
#freq<-1000
#init<-0 
#bd.2010$inc<-as.numeric(as.character(bd.2010$inc))
#fin<-(abs(max(bd.2010$inc,na.rm=TRUE))+5)
#ival<-c(init,bd.2010$inc,fin)
#len<-10000
#s<-sapply(2:length(ival),function(i){
#  seq(ival[i-1],ival[i],length.out=len)
#})
#s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
#bd.2010.ind<-data.frame(s)
#names(bd.2010.ind)[1]=c("inc")
#bd.2010.ind$inc<-bd.2010.ind$inc/1000
@

<<Comparing 2003 to 2010>>=
library(reldist, quietly=TRUE, warn.conflicts = FALSE)

# imputing pseudo-individual data to use reldist
# we cut at the 5th and 95th percentile because it is unclear what values to use to extrapolate
bd.2003 <- rbind(c(0,0),bd.2003)
ival<-bd.2003$inc
perval<-bd.2003$percentile
bd.2003.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

# Probability Density Function

density1 <- density(bd.2003.ind)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density",
     axes = FALSE)
title(main="2003 vs 2010",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(1200,1200),y=c(0.0116031,0.0116031))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("2003","2010"))
density2 <- density(bd.2010.ind)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Variante mit Log

density1 <- density(log(bd.2003.ind))
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "log(taxable income)", ylab = "density",
     axes = FALSE)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(5,5),y=c(0.5655167,0.5655167))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("2003","2010"))
density2 <- density(log(bd.2010.ind))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

par(mfrow=c(1,3))
g10 <- reldist(y=bd.2010.ind$inc, yo=bd.2003.ind$inc,
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               ylim=c(0.5,2),
               bar=TRUE, quiet=FALSE,
               xlab="Proportion of 2003 Distribution")
title(main=paste("Overall realtive density"))
abline(h=1,lty=2)
g1A <- reldist(y=bd.2010.ind$inc, yo=bd.2003.ind$inc,
               show="effect",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2), ylab="",
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               xlab="Proportion of 2003 Distribution")
title(main=paste("Effect of Median shift"))
abline(h=1,lty=2)
gA0 <- reldist(y=bd.2010.ind, yo=bd.2003.ind,
               smooth=0.4, ci=FALSE,
               show="residual",
               entropy=NA,
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2), ylab="",
               yolabs=seq(-1,3,by=0.5),
               discrete=FALSE,
               xlab="Proportion of 2003 Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))

# Polarization index

wgt<-rep(1,length(bd.2003.ind))



format(rpy(y=bd.2010.ind,yo=bd.2003.ind,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=bd.2010.ind,yo=bd.2003.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=bd.2010.ind,yo=bd.2003.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

@

% Report Polarization index

\emph{Gini coefficients considering mean-tested benefits}

% Wollen wir das ?berhaupt machen?

\subsection{Measuring inequality}

% Zero-shares (alter Textbaustein)
%Estimation using population statistics (1945/46-1993/94) and official tax administration statistics (1995/96 and later) 
% Das allenfalls in der Methodensection machen?
% Vergleich mit der Dell-Reihe zu Non-fillers
% Überschneidungen gib es leider nicht 
% Interessant wäre es auch, zu sehen ob es Brüche in den Zeitreihen der Zahl der Steuerpflichtigen und jener ohne Besteuerung gibt.

\subsection{Population coverage}

\subsubsection{Normal versus special cases}

The FTA stopped to publicly report data for special cases after tax period 1993/94. 
For more recent periods however we can compare already calculated percentiles provided by the FTA\footnote{These calculations were done on commission of the FTA within the SNF project Sinergia Nr. 130648 "The Swiss Confederation: A Natural Laboratory for Research on Fiscal and Political Decentralization" by Raphael Parchet and Stefanie Brilon in coordination with Prof. Dr. Marius Brülhart.} which are based on both special and normal cases to normal cases alone.
We will have a look at both, the 1993/94 period as the last period where both 
numbers were reported as well as 2010 where we compare data from the same source (FTA)
but based on different reporting (aggregated data vs. percentiles).

%ABBILDUNGEN ZUM VERGLEICH NORMAL-/SONDERFÄLLE
<<specialcases9394, echo=FALSE,warning=FALSE,hide=TRUE>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(ggplot2)
#library(reldist)
normal <- read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t")
normal <- select(normal, -G_reink,-G_taxed,-ppop0,-G_steink0)
#normal <- normal %.% select(-G_reink, -G_taxed, -ppop0, -G_steink0)
pooled <- read.csv("../../data/ginis_und_perzentile_beides.csv",sep="\t")
#special <- read.csv("data/ginis_und_perzentile_sonder.csv",segep="\t")
normal$case <- "normal case"
#special$case <- "special case"
pooled$case <- "pooled, normal and special cases"
d<-rbind(normal,pooled)
d<-d %.% 
  filter(kanton=="CH",steuerperiode==1993.5)

start <- which(names(d)=="p1")
end <- which(names(d)=="p99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,99)
normal <- data.frame(t(d[1,start:end]),percentile,case="normal")
pooled <- data.frame(t(d[2,start:end]),percentile,case="pooled")
names(normal)[1]=c("inc")
names(pooled)[1]=c("inc")
percentiles <- rbind(normal,pooled)  
ggplot(percentiles, aes(x=percentile,y=inc,group=case,colour=case))+
	geom_line()+theme_bw()+
	scale_colour_grey()+
	xlab("Percentile")+ylab("taxable income")+
	ggtitle("Taxable incomes of normal and special cases 1993/94")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))


#plot relative distribution
rel <- data.frame(pooled$inc,normal$inc,pooled$percentile)
rel$change <- rel$pooled.inc/rel$normal.inc
ggplot(rel, aes(x=pooled.percentile,y=change))+
	geom_line()+theme_bw()+
	scale_colour_grey()+
	geom_line(linetype="dashed",aes(y=1),size=1)+
	xlab("Percentile")+ylab("taxable income")+
	ggtitle("Taxable incomes of normal versus special cases 1993/94")

#steuerpflichtige estv / stpf bruelhart
#1- (2762419 / 3268548)


# imputing pseudo-individual data to use reldist
# we cut at the 5th and 95th percentile because it is unclear what values to use to extrapolate
ival<-na.omit(normal$inc[-1])
perval<-normal$percentile[-1]
normal_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

ival<-na.omit(pooled$inc)
perval<-pooled$percentile[-1]
pooled_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))


# Probability Density Function

density1 <- density(normal_i)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="normal cases vs pooled, normal and special cases 1993/94",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(60,60),y=c(0.019,0.019))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("normal cases","pooled, normal and special cases"))
density2 <- density(pooled_i)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Relative Distribution

par(mfrow=c(1,3))
a<-reldist(y=pooled_i, yo=normal_i,
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               ylim=c(0.5,2.0),
               bar=TRUE, quiet=FALSE,
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Overall relative density 1993/94"))
abline(h=1,lty=2)
b<-reldist(y=pooled_i, yo=normal_i,
               show="effect",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Effect of Median shift"))
abline(h=1,lty=2)
c<-reldist(y=pooled_i, yo=normal_i,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               yolabs=seq(-1,3,by=0.5),
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))
@

1993/94 including special cases changes the distribution slightly at both ends. Special cases have a slightly lower median income and therefore are more frequent in the lower percentiles and less frequent in the upper percentiles. In addition there is an effect of shape: the distribution of special cases is more skewed so that lower percentiles show lower incomes and higher percentiles show higher incomes compared to just normal cases.

<<specialcases10, echo=FALSE,warning=FALSE,hide=TRUE>>=
library(foreign)
library(ggplot2)
#library(reldist)
normal <- filter(read.csv("../../data/ginis_und_perzentile_normal.csv",sep="\t"),kanton=="CH",steuerperiode==2010)
start <- which(names(normal)=="p1")
end <- which(names(normal)=="p99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,99)
normal <- data.frame(t(normal[1,start:end]),percentile)
names(normal)[1]=c("inc")

#bruelhart data
pooled <- filter(read.csv("../../data/data_Schweiz.csv",sep=";"), Veranlagungsperiode==2010, Einheit=="Total")
start <- which(names(pooled)=="p1")
p95 <- which(names(pooled)=="p95")
end <- which(names(pooled)=="p99")
pooled <- data.frame(t(pooled[1,c(start:p95,end)]),percentile)
names(pooled)[1]=c("inc")
pooled$inc<-pooled$inc/1000 #adjust scale
normal$case <- "normal case"
pooled$case <- "pooled, normal and special cases"
percentiles <- rbind(normal,pooled)
ggplot(percentiles, aes(x=percentile,y=inc,group=case,colour=case))+
	geom_line()+theme_bw()+
	scale_colour_grey()+
	xlab("Percentile")+ylab("taxable income")+
	ggtitle("Taxable incomes of normal and special cases 2010")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))


#plot relative distribution
rel <- data.frame(pooled$inc,normal$inc,pooled$percentile)
rel$change <- rel$pooled.inc/rel$normal.inc
ggplot(rel, aes(x=pooled.percentile,y=change))+
	geom_line()+theme_bw()+
	geom_line(linetype="dashed",aes(y=1),size=2)+
	scale_colour_grey()+
	xlab("Percentile")+ylab("taxable income")+
	ggtitle("Taxable incomes of normal versus special cases 2010")

#steuerpflichtige estv / stpf bruelhart
#1- (3422210 / 3689063)

# imputing pseudo-individual data to use reldist
# we cut at the 95th percentile because it is unclear what values to use to extrapolate
ival<-na.omit(c(0,normal$inc))
perval<-c(0,normal$percentile)
normal_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

#nur bis 95
ival<-na.omit(c(0,pooled$inc[-15]))
perval<-c(0,pooled$percentile)
pooled_i<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))


# Probability Density Function

density1 <- density(normal_i)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="normal cases vs pooled, normal and special cases 2010",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(65,65),y=c(0.016,0.016))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("normal cases","pooled, normal and special cases"))
density2 <- density(pooled_i)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Relative Distribution

par(mfrow=c(1,3))
a<-reldist(y=pooled_i, yo=normal_i,
               smooth=0.4, ci=FALSE,
               ylim=c(0.5,2.0),
               bar=TRUE, quiet=FALSE,
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Overall relative density 2010"))
abline(h=1,lty=2)
b<-reldist(y=pooled_i, yo=normal_i,
               show="effect",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               smooth=0.4, ci=FALSE,
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Effect of Median shift"))
abline(h=1,lty=2)
c<-reldist(y=pooled_i, yo=normal_i,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of Normal-Case-Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))

wgt<-rep(1,length(normal_i))


format(rpy(y=pooled_i,yo=normal_i,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=pooled_i,yo=normal_i,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=pooled_i,yo=normal_i,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index

gini(normal_i)-gini(pooled_i)

@

2010 the picture is similar but more apparent: There is a small effect of median shift lowering incomes in the lowest percentiles. The effect of shape however contributes most.


% Auf neuste Zahlen anpassen

%As we can see from figure~\ref{fig:specialcases93942} and \ref{fig:specialcases092}, special cases differ strongly 
%from normal cases within the low and top percentiles. Within the tax period 1993/94 the fifth percentile of 
%normal cases is 15.8\% higher than the fifth percentile of the combines data while the 95\% percentile of 
%normal cases is even 0.7\% lower if one leaves out special cases. This indicates special cases are very 
%different from normal cases as the share of special cases is only 15.5\%.\footnote{1993/94 there were 2.76 
%million tax units defined as being normal cases compared to 0.51 million special cases.}
%In 2009 the situation has the same pattern. The fifth percentile of normal cases has 11\% higher taxable 
%income compared to data where special cases are included. The five percent top incomes are 4.9\% higher 
%within all cases compared to normal cases only. The share of special cases however decreased 
%to 7.2\%.\footnote{2009: 3.42 million normal cases, 0.27 million special cases}



\emph{Income measures with and without zeros}

taxable income with and without zeros

<<with_without_zeros,warning=FALSE>>=
dflong <- melt(df[,c("G_steink","G_steink0","kanton","steuerperiode")], id=c("kanton","steuerperiode"))
names(dflong)[3]<-"Type"
names(dflong)[4]<-"Gini"
levels(dflong$Type)<-c("without zeros","including zeros")
ggplot(dflong[dflong$kanton=="CH" & dflong$steuerperiode>=1995.5,], 
       aes(x=steuerperiode,y=Gini,shape=Type,linetype=Type))+
  scale_y_continuous(limits=c(0.18,0.6))+
  scale_x_continuous(limits=c(1994,2012),breaks=number_ticks(10)) +
  geom_line(size=0.5)+
  geom_point(aes(shape=Type),size=3)+
  theme_bw()+
  xlab("tax period")+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))
#ggplot(dflong[dflong$steuerperiode>=1995.5,], aes(x=steuerperiode,y=Gini,shape=Type,linetype=Type))+geom_line()+facet_wrap(~kanton)+theme_bw()+xlab("tax period")+theme(axis.text.x = element_text(angle = 60, hjust = 1))+theme(legend.justification=c(1,0),legend.position=c(1, 0))
@

<<with_without_zeros RelDist,warning=FALSE>>=
bd.2010 <- filter(read.csv("../../data/data_Schweiz.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Total")
bd.0.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Total")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.0.2010<- data.frame(t(bd.0.2010[1,start:end]),percentile)
names(bd.0.2010)[1]=c("inc")

bd.0.2010 <- rbind(c(0,0),bd.0.2010)
ival<-bd.0.2010$inc
perval<-bd.0.2010$percentile
bd.0.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

# Prop-Density Plot
density1 <- density(log(bd.2010.ind))
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "taxable income", ylab = "density"
     #axes = FALSE,
     #xlim = c(-50, 200),
     #ylim=c(0,0.0116031)
     )
title(main="all tax units vs without non-taxed",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(6,6),y=c(0.6,0.6))
legend(fig1legend,lty=1:2, bty="n",
       legend=c("without non-taxed","all tax units"))
density2 <- density(log(bd.0.2010.ind))
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

gA0 <- reldist(y=bd.2010.ind, yo=bd.0.2010.ind,
               smooth=0.4, ci=FALSE,
               show="residual",
               entropy=NA,
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2), ylab="",
               yolabs=seq(-1,3,by=0.5),
               discrete=FALSE,
               xlab="Proportion of 2010 Distribution (including non-taxed)")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)


# Polarization index

wgt<-rep(1,length(bd.2010.ind))



format(rpy(y=bd.2010.ind,yo=bd.0.2010.ind,
           ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Median Index, middle value is the estimate 
format(rpluy(y=bd.2010.ind,yo=bd.0.2010.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE),
       digits=3) # Lower Index
format(rpluy(y=bd.2010.ind,yo=bd.0.2010.ind,
             ywgt=wgt,yowgt=wgt,pvalue=FALSE,
             upper=TRUE),
       digits=3) # Upper index


@

Including zeros leads to significantly higher gini coefficients. However we must keep in mind, that these might be artificially high values as we assume zero income for everyone in the zero group. We can conclude more from the graphic: the ratio between both measures seems to be quite constant although for aggregate Switzerland but there are minor deviations for multiple cantons as well as strong deviations for the cantons Geneva and Ticino. However the problems seem not to result from a shift in the zero-share over time but they are specific for the time-period when the tax system changed. 

\emph{comparison of tax-data and survey data distribution}

<<setup_data>>=
library(dplyr, quietly=TRUE, warn.conflicts = FALSE)
library(ggplot2)
library(reldist, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)

bd.0$Jahr <- as.numeric(substr(bd.0$Veranlagungsperiode,1,4))
bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] <- bd.0$Jahr[nchar(as.character(bd.0$Veranlagungsperiode))>4] - 2
bd.2010<-bd.0 %.% 
  filter(Jahr==2010,Einheit=="Total")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010.ind<-bd.2010.ind/1000

######
# Old Version
# Get Brülhartdata for 2010
estv2010 <- read.csv("../../data/estv_normal_sonder_mitNuller_stE_2010.csv",sep=";")
###
# Select percentiles for all cases (total)
estv2010.total<-estv2010[c(18:38),c(1,4)]
# Simulate individual data points
# cumulative probabilites
cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
# probabilities
prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
# extreme values beyond x (to sample)
#freq<-max(normal$anz_pflichtige)
freq<-3000
init<-0
fin<-(abs(max(estv2010.total$Total,na.rm=TRUE))+5)
# generate the sequence to take pairs from
ival<-c(init,estv2010.total$Total,fin)
len<-10000 # sequence of each pair
s<-sapply(2:length(ival),function(i){
  seq(ival[i-1],ival[i],length.out=len)
})
s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
estv2010.total.ind<-data.frame(s)
names(estv2010.total.ind)[1]=c("inc")
estv2010.total.ind$inc<-estv2010.total.ind$inc/1000


# HABE - 2010 all cases 

#####################################################
#         ACHTUNG: Bisher ohne Gewichte!            #
#####################################################
try(habe0911<-read.table("C:/Users/Hackstutz/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
g2009 <- read.csv("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE2009_Gewichte_140625UOe.txt",sep="\t")
g2010 <- read.csv("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE2010_Gewichte_140625UOe.txt",sep="\t")
g2011 <- read.csv("C:/Users/rudi/Dropbox/Ungleichheit/HABE/HABE091011/HABE2011_Gewichte_140625UOe.txt",sep="\t")
names(g2009)[3:4]<-c("SRH","Gewicht")
names(g2010)[3:4]<-c("SRH","Gewicht")
names(g2011)[3:4]<-c("SRH","Gewicht")
jg091011 <- rbind(g2009,g2010,g2011)
all.equal(match(jg091011$HaushaltID,habe0911$HaushaltID),1:nrow(habe0911))
habe0911$jahresgewicht <- jg091011

habe10<-habe0911 %.% 
  filter(Jahr08==2010)
habe10<-data.frame(habe10$VerfuegbaresEinkommen08)
names(habe10)<-"inc_habe"
habe10$inc_habe[habe10$inc_habe<0]<-0 # One values is -20'000
habe10$inc_habe<-habe10$inc_habe*12/1000 # transform from monthly income to income per year



# Probability density Function

density1 <- density(habe10$inc_habe)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "Einkommen", ylab = "density",
     axes = FALSE,
     #xlim = c(-30, 1400),
     ylim=c(0,1.151e-02 ))
title(main="FTA vs HBS income distribution",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(400,400),y=c(1.097e-02,1.097e-02))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("HBS","FTA"))
density2 <- density(bd.2010.ind)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Relative Distribution


gA0 <- reldist(y=bd.2010.ind, yo=habe10$inc_habe,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of HBS Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)


########################
# Separate comparison for unmarried

# Select married - ESTV

bd.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Verheiratet / mariés")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010.ind<-bd.2010.ind/1000


#######
# Old Version
estv2010.married<-estv2010[c(18:38),c(1,2)]
names(estv2010.married)[2]=c("married")
##
# Simulate individual data points
# Percentile-Plot (descriptive  purpose)
# cumulative probabilites
cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
# probabilities
prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
# extreme values beyond x (to sample)
#freq<-max(normal$anz_pflichtige)
freq<-3000
init<-0
fin<-(abs(max(estv2010.married$married,na.rm=TRUE))+5)
# generate the sequence to take pairs from
ival<-c(init,estv2010.married$married,fin)
len<-10000 # sequence of each pair
s<-sapply(2:length(ival),function(i){
  seq(ival[i-1],ival[i],length.out=len)
})
s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
estv2010.married.ind<-data.frame(s)
names(estv2010.married.ind)[1]=c("inc")
estv2010.married.ind$inc<-estv2010.married.ind$inc/1000
#####



# Select married - HABE
try(habe0911<-read.table("C:/Users/Hackstutz/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
habe10<-habe0911 %.% 
  filter(Jahr08==2010)
habe10.married<-habe0911 %.% 
  filter(Familientyp08>130,Jahr08==2010)
habe10.married<-data.frame(habe10.married$VerfuegbaresEinkommen08)
names(habe10.married)<-"inc_habe"
habe10.married$inc_habe[habe10.married$inc_habe<0]<-0 # One values is -20'000
habe10.married$inc_habe<-habe10.married$inc_habe*12/1000 # transform from monthly income to income per year

# Probability Density Function

density1 <- density(habe10.married$inc_habe)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "Einkommen", ylab = "density",
     axes = FALSE,
     xlim = c(min(rbind(density1$x,density2$x)), 800),
     ylim=c(0,max(rbind(density1$y,density2$y))))
title(main="FTA vs HBS income distribution",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(median(rbind(density1$x,density2$x)),median(rbind(density1$x,density2$x))),y=c(max(rbind(density1$y,density2$y)),max(rbind(density1$y,density2$y))))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("HBS","FTA"))
density2 <- density(bd.2010.ind)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)

# Relative Distribution




gA0 <- reldist(y=bd.2010.ind, yo=habe10.married$inc_habe,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.0), ylab="",
               xlab="Proportion of HBS Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)



#################
# Separate comparison for unmaried


bd.2010 <- filter(read.csv("../../data/data_Schweiz_mitNull.csv", header=TRUE,sep=";"),Veranlagungsperiode==2010,Einheit=="Unverheiratet / non-mariés")
start <- which(names(bd.2010)=="p1")
end <- which(names(bd.2010)=="p99_99")
percentile <- c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)
bd.2010<- data.frame(t(bd.2010[1,start:end]),percentile)
names(bd.2010)[1]=c("inc")
bd.2010 <- rbind(c(0,0),bd.2010)
ival<-bd.2010$inc
perval<-bd.2010$percentile
bd.2010.ind<-unlist(sapply(2:length(ival),function(i){
  len=(perval[i]-perval[i-1])*100
  seq(ival[i-1],ival[i],length.out=len)
}))

bd.2010.ind<-bd.2010.ind/1000


##
# Unmarried ESTV

estv2010.unmarried<-estv2010[c(18:38),c(1,3)]
names(estv2010.unmarried)[2]=c("unmarried")
##
# Simulate individual data points
# Percentile-Plot (descriptive  purpose)
# cumulative probabilites
cum.p<-c(1,5,10,20,25,30,40,50,60,70,75,80,90,95,96,97,98,99,99.5,99.9,99.99)/100
# probabilities
prob<-c(cum.p[1],diff(cum.p), 1-0.9999)
# extreme values beyond x (to sample)
#freq<-max(normal$anz_pflichtige)
freq<-3000
init<-0
fin<-(abs(max(estv2010.unmarried$unmarried,na.rm=TRUE))+5)
# generate the sequence to take pairs from
ival<-c(init,estv2010.unmarried$unmarried,fin)
len<-10000 # sequence of each pair
s<-sapply(2:length(ival),function(i){
  seq(ival[i-1],ival[i],length.out=len)
})
s<-sample(s,freq,prob=rep(prob, each=len),replace=T)
estv2010.unmarried.ind<-data.frame(s)
names(estv2010.unmarried.ind)[1]=c("inc")
estv2010.unmarried.ind$inc<-estv2010.unmarried.ind$inc/1000


# Select unmarried - HABE
try(habe0911<-read.table("C:/Users/Hackstutz/Dropbox/Ungleichheit/HABE/HABE091011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
try(habe0911<-read.table("P:/WGS/FBS/ISS/Projekte laufend/SNF Ungleichheit/Datengrundlagen/HABE/2009 bis 2011/HABE091011_Standard_130717UOe.txt", header=TRUE),silent=TRUE)
habe10<-habe0911 %.% 
  filter(Jahr08==2010)
habe10.unmarried<-habe0911 %.% 
  filter(Familientyp08<140,Jahr08==2010)
habe10.unmarried<-data.frame(habe10.unmarried$VerfuegbaresEinkommen08)
names(habe10.unmarried)<-"inc_habe"
habe10.unmarried$inc_habe[habe10.unmarried$inc_habe<0]<-0 # One values is -20'000
habe10.unmarried$inc_habe<-habe10.unmarried$inc_habe*12/1000 # transform from monthly income to income per year


# Probability Density Function

density1 <- density(habe10.unmarried$inc_habe)
plot(x = (density1$x), y = density1$y, type = "l",
     xlab = "Einkommen", ylab = "density",
     axes = FALSE,
     xlim = c(min(rbind(density1$x,density2$x)), 800),
     ylim=c(0,max(rbind(density1$y,density2$y))))
title(main="FTA vs HBS income distribution",cex=0.6)
axis(side = 1)
axis(side = 2)
fig1legend <- list(x=c(median(rbind(density1$x,density2$x)),median(rbind(density1$x,density2$x))),y=c(max(rbind(density1$y,density2$y)),max(rbind(density1$y,density2$y))))
legend(fig1legend,lty=1:2,cex=1, bty="n",
       legend=c("HBS","FTA"))
density2 <- density(bd.2010.ind)
lines(x = (density2$x), y = density2$y, type = "l",lty=2)


# Relative Distribution

par(mfrow=c(1,3))
g10 <- reldist(y=estv2010.unmarried.ind$inc, yo=habe10.unmarried$inc_habe,
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               ylim=c(0.5,5.0),
               bar=TRUE, quiet=FALSE,
               xlab="Proportion of HBS Distribution")
title(main=paste("Overall realtive density"))
abline(h=1,lty=2)
g1A <- reldist(y=estv2010.unmarried.ind$inc, yo=habe10.unmarried$inc_habe,
               show="effect",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,5.0), ylab="",
               smooth=0.4, ci=FALSE,
               yolabs=seq(-1,3,by=0.5),
               xlab="Proportion of HBS Distribution")
title(main=paste("Effect of Median shift"))
abline(h=1,lty=2)
gA0 <- reldist(y=bd.2010.ind, yo=habe10.unmarried$inc_habe,
               smooth=0.4, ci=FALSE,
               show="residual",
               bar=TRUE, quiet=FALSE,
               ylim=c(0.5,2.5), ylab="",
               xlab="Proportion of HBS Distribution")
title(main=paste("Effect of different shape"))
abline(h=1,lty=2)
par(mfrow=c(1,1))
@


\subsection{Intertemporal comparison}



<<benplot>>=
 ### libs
library(reshape, quietly=TRUE, warn.conflicts = FALSE)
library(foreign)
library(dplyr)
library(reldist)
library(ggplot2)

### Fetch Ginis from different survey data
number_ticks <- function(n) {function(limits) pretty(limits, n)}
swissGini<-read.csv("../../data/swissGini.csv",header=TRUE,sep=";")

### Ginis from Bens File (for imputed gap)
ben <- filter(read.dta("../../data/estv-gini-kt.dta"),kanton=="CH2")

### and for the rest of Ginis:
estv <- read.dta("../../data/steuerdaten20140522_stata12.dta")

estv_gini <- estv %.% 
  filter(kanton=="CH",eink_art=="Nach steuerbarem Einkommen",fall=="Normalfälle",anz_pflichtige>0,steuerperiode!=1945.5) %.% 
  select(steuerperiode, steink, kanton, eink_ll, eink_ul,anz_pflichtige) %.%
  group_by(factor(steuerperiode)) %.%
  mutate(mean_steink=steink/anz_pflichtige) %.%
  summarise(gini(mean_steink,weights=anz_pflichtige))

names(estv_gini) <- c("Year","FTA")
estv_gini$Year<-as.numeric(as.character(estv_gini$Year))
estv_gini$Year[estv_gini$Year<2003] <- estv_gini$Year[estv_gini$Year<2003]-2


all_gini <- data.frame("Year"=seq(1916,2012,by=0.5))
all_gini$FTA <- estv_gini$FTA[match(all_gini$Year,estv_gini$Year)]
all_gini$HBS <- swissGini$HABE[match(all_gini$Year,swissGini$Year)]
all_gini$EU.SILC <- swissGini$EU.SILC[match(all_gini$Year,swissGini$Year)]
all_gini$LIS <- swissGini$LIS[match(all_gini$Year,swissGini$Year)]
all_gini$FTA_imp <- ben$gini[match(all_gini$Year,ben$jahr)]

all_gini_long<-melt(all_gini,id="Year")

names(all_gini_long) <- c("Year","Data","Gini")
ggplot(data=na.omit(all_gini_long),
  aes(y=Gini,x=Year,shape=Data,linetype=Data))+
  ylab("Gini from different sources") +
  scale_y_continuous(limits=c(0.18,0.4)) +
  scale_x_continuous(limits=c(1915,2012),breaks=number_ticks(10)) +
  geom_point(size=3)+
  geom_line()+
  theme_bw()+
  theme(legend.justification=c(0,1),legend.position=c(0, 1))


@